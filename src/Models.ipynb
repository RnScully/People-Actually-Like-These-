{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T21:57:35.507710Z",
     "start_time": "2020-02-05T21:57:34.383209Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, SCORERS\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T21:57:43.799160Z",
     "start_time": "2020-02-05T21:57:43.783587Z"
    },
    "code_folding": [
     0,
     5,
     15
    ]
   },
   "outputs": [],
   "source": [
    "def save_model(model,name):\n",
    "    file_ext= '.sav'\n",
    "    path = 'models/'\n",
    "    pickle.dump(model, open(path+name+file_ext, 'wb'))\n",
    "    \n",
    "def predict_one(string, model_name, vectorizor_name):\n",
    "    \n",
    "    path = 'models/'\n",
    "        \n",
    "    tfid = pickle.load(open(path+vectorizor_name, 'rb'))\n",
    "    tfidfed = tfid.transform([string])\n",
    "\n",
    "    model = pickle.load(open(path+model_name, 'rb'))\n",
    "    return model.predict(tfidfed)\n",
    "\n",
    "def predict_many(review_list, model_name, vectorizor_name):\n",
    "    path = 'models/'\n",
    "        \n",
    "    tfid = pickle.load(open(path+vectorizor_name, 'rb'))\n",
    "    tfidfed = tfid.transform(review_list)\n",
    "\n",
    "    model = pickle.load(open(path+model_name, 'rb'))\n",
    "    return model.predict(tfidfed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load things stored from other pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr  = np.load('data/english_arr.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T21:57:49.165825Z",
     "start_time": "2020-02-05T21:57:48.422555Z"
    }
   },
   "outputs": [],
   "source": [
    "ngr  = np.load('data/2grams.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize and Stem, or: Pre-handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = arr[:,3]\n",
    "ratings = arr[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good vs bad rating 4,5 will be good (1), -1, 1,2,3 will be bad (0)\n",
    "\n",
    "y = ratings\n",
    "gvb = []\n",
    "\n",
    "for i in y:\n",
    "    if i <=4:\n",
    "        gvb.append(0)\n",
    "    else:\n",
    "        gvb.append(1)\n",
    "        \n",
    "\n",
    "np.save('gvbtrain.npy', gvb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39644"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gvb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-Selections\n",
    "gvb is a training set that will let the model predict good/bad valences, if a rating is 4 or 5, gvb = 1\n",
    "\n",
    "FourFive is a sub-selection of the whole dataset with just the 4 and five ratings, to try and train a this is best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(stop_words ='english', lowercase = False, max_features = 5000)\n",
    "tfidfed = tfid.fit_transform(lang)\n",
    "\n",
    "X = tfidfed\n",
    "y = ratings.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, gvb, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T21:58:10.306940Z",
     "start_time": "2020-02-05T21:58:10.161855Z"
    }
   },
   "outputs": [],
   "source": [
    "sngr = [' '.join(item) for item in ngr]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T21:58:17.927848Z",
     "start_time": "2020-02-05T21:58:12.101780Z"
    }
   },
   "outputs": [],
   "source": [
    "ngramTFV = TfidfVectorizer(lowercase = False, max_features = 5000)\n",
    "ngramX = ngramTFV.fit_transform(sngr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T21:58:17.945082Z",
     "start_time": "2020-02-05T21:58:17.929786Z"
    }
   },
   "outputs": [],
   "source": [
    "gvb  = np.load('gvbtrain.npy', allow_pickle = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ngramX, gvb, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6639914392723382"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "knn_class = KNeighborsClassifier(n_neighbors = 18, n_jobs =-1)\n",
    "knn_class.fit(X_train, y_train)\n",
    "knn_class.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An early random forest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=True, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest1 = RandomForestClassifier(min_samples_split = 10, oob_score=True, n_jobs =-1, n_estimators = 100)\n",
    "forest1.fit(X, gvb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8460296640096862"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest1.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(tfid, 'tf84')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest with more trees, mowed down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=-1, oob_score=True, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manysaplings = RandomForestClassifier(min_samples_split = 10, oob_score=True, n_jobs =-1, n_estimators = 1000)\n",
    "manysaplings.fit(X, gvb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8533699929371406"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manysaplings.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest on Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=-1, oob_score=True, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramforest = RandomForestClassifier(min_samples_split = 10, oob_score=True, n_jobs =-1, n_estimators = 1000)\n",
    "ngramforest.fit(ngramX, gvb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8543537483604077"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramforest.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25754"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gvb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, gvb, test_size=0.33)\n",
    "\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "grad_boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.7440984902676857, Testing score: 0.718183902774593\n",
      "tn   fp   fn   tp\n",
      "8025 383 3304 1371\n",
      "precision: 0.7816419612314709 recall: 0.2932620320855615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                            n_iter_no_change=None, presort='auto',\n",
       "                            random_state=None, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " 0.7440984902676857,\n",
       " 0.718183902774593,\n",
       " 0.7816419612314709,\n",
       " 0.2932620320855615]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_score(grad_boost, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient boosting with the n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ngramX, gvb, test_size=0.33)\n",
    "\n",
    "ngram_gboost = GradientBoostingClassifier(max_features = )\n",
    "ngram_gboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.7490681826738451, Testing score: 0.7307956890621418\n",
      "tn   fp   fn   tp\n",
      "8040 410 3112 1521\n",
      "precision: 0.787674779906784 recall: 0.3282969997841571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7490681826738451, 0.7307956890621418, 0.787674779906784, 0.3282969997841571]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_score(ngram_gboost, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch on ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-05T21:59:15.309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 540 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.0s\n",
      "/home/robert/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 51.1min\n"
     ]
    }
   ],
   "source": [
    "ngram_grid = {'max_depth': [1,2, 3, 4, 10],\n",
    "                      'max_features': ['sqrt', 'log2', None],\n",
    "                      'min_samples_split': [2, 4, 10],\n",
    "                      'min_samples_leaf': [1, 2, 4],\n",
    "                      'n_estimators':[10,50,100,200]}                        \n",
    "                           \n",
    "\n",
    "\n",
    "\n",
    "gbr_gridsearch = GridSearchCV(GradientBoostingClassifier(),\n",
    "                             ngram_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='f1')\n",
    "gbr_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_score(model, X_test, y_test):\n",
    "    '''\n",
    "    a function that reports the accuracy of the model.\n",
    "    Attributes:\n",
    "    models (lst): a list of instansiated models to test\n",
    "    Returns:\n",
    "    out array, model name, training score, testing score, precision, recall\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    training_score = model.score(X_train, y_train)\n",
    "    testing_score = model.score(X_test, y_test)\n",
    "    print('Training score: {}, Testing score: {}'.format(training_score, testing_score))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,model.predict(X_test)).ravel()\n",
    "    precision = tp/(fp+tp)\n",
    "    recall = tp/(fn+tp)\n",
    "    print('tn', '  fp', '  fn', '  tp')\n",
    "    print(tn, fp, fn, tp)\n",
    "    print('precision: '+str(precision), 'recall: '+ str(recall))\n",
    "    out_lst = [training_score, testing_score, precision, recall]\n",
    "    return out_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'rf84.sav' is an 84% accurate random forest model. \n",
    "- 'tf84.sav' is the vectorizer formulated to work for the 84% rf, with 5000 rows. Can fit into other things with 500 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-05T22:10:23.313Z"
    }
   },
   "outputs": [],
   "source": [
    "string = \"fuck this book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-05T22:10:26.043Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_one(string, 'rf84.sav', 'tf84.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitanaconda3virtualenv4689841a946143dd80c9fcc86c644564"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
